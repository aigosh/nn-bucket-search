{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/embeddings.csv', chunksize=10000, names=['image', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# def new_euclidean_distances(X, Y=None, Y_norm_squared=None, squared=False): \n",
    "#     return cosine_similarity(X,Y)\n",
    "\n",
    "# # monkey patch (ensure cosine dist function is used)\n",
    "# from sklearn.cluster import k_means_\n",
    "# k_means_.euclidean_distances = new_euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_file = '../data/embeddings.csv'\n",
    "train_file = '../data/train.csv'\n",
    "validation_file = '../data/validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_records([], columns=['image', 'label'])\n",
    "# df.to_csv(train_file, index=False)\n",
    "# df.to_csv(validation_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(file_path, train_file, validation_file, chunksize=10000):\n",
    "    count = 0\n",
    "    df = pd.read_csv(file_path, chunksize=chunksize, header=0)\n",
    "    for i, chunk in enumerate(df):\n",
    "        print(count + len(chunk))\n",
    "        X = np.array([np.fromstring(item[1:-1], dtype=np.float32, sep=' ') for item in chunk['image'].values])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, chunk['label'].values, test_size=0.3,\n",
    "                                                            random_state=42, shuffle=True)\n",
    "#         print(X_train)\n",
    "        \n",
    "        data = list(zip(X_train, y_train))\n",
    "        df = pd.DataFrame.from_records(data, columns=['image', 'label'])\n",
    "        df.to_csv(train_file, index=False, header=False, mode='a')\n",
    "        \n",
    "        data = list(zip(X_test, y_test))\n",
    "        df = pd.DataFrame.from_records(data, columns=['image', 'label'])\n",
    "        df.to_csv(validation_file, index=False, header=False, mode='a')\n",
    "        \n",
    "        count += len(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split(embeddings_file, train_file, validation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedAccuracyMeter():\n",
    "    def __init__(self):\n",
    "        self.y = []\n",
    "        self.y_hat = []\n",
    "        \n",
    "    def add(self, y, y_hat):\n",
    "        self.y.append(y)\n",
    "        self.y_hat.append(y_hat)\n",
    "        \n",
    "    def calculate(self):\n",
    "        y = torch.cat(self.y, 0)\n",
    "        y_hat = torch.cat(self.y_hat, 0)\n",
    "        \n",
    "        return torch.tensor([self.accuracy(y, y_hat) \n",
    "                            for y, y_hat in list(zip(y, y_hat))])\n",
    "    def accuracy(self, y, y_hat):\n",
    "        tp = torch.sum(y & y_hat).type(torch.float32)\n",
    "        tn = torch.sum(~y & ~y_hat).type(torch.float32)\n",
    "        p_count = torch.sum(y).type(torch.float32)\n",
    "        n_count = torch.sum(~y).type(torch.float32)\n",
    "        \n",
    "        return (tp / p_count + tn / n_count) / 2\n",
    "    def reset(self):\n",
    "        self.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x1, x2, dim=1):\n",
    "    x1 = normalize(x1, dim=dim)\n",
    "    x2 = normalize(x2, dim=dim)\n",
    "    return 1.0 - torch.sum(x1 * x2, dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineDistance(nn.Module):\n",
    "    def __init__(self, dim=1):\n",
    "        super(CosineDistance, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        return cosine_distance(x1, x2, dim=self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_string_array(arr, dtype=None):\n",
    "    return np.fromstring(arr[1:-1], dtype=None, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_string_ndarray(arr, dtype=None):\n",
    "    return np.array([read_string_array(target, dtype=None) for target in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chunk(chunk, device=torch.device('cpu')):\n",
    "    X = np.array(chunk['image'].values.tolist(), dtype=np.float32)\n",
    "    y = chunk['label'].to_numpy(dtype=np.int)\n",
    "    \n",
    "    \n",
    "    X = torch.from_numpy(X).to(device)\n",
    "    y = torch.from_numpy(y).to(device)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_y_true(y_train, y_test):\n",
    "#     return y_test[:, None] == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_y_hat(similiarity, treshold):\n",
    "#     return similiarity > treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(X_train, y_train, X_test, y_test, treshold):\n",
    "#     sim = cosine_similarity(target, X_train)\n",
    "                \n",
    "#     y_hat = get_y_hat(sim, treshold)\n",
    "#     y = get_y_true(y_train, y_test)\n",
    "    \n",
    "#     return y, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.__count = 0\n",
    "    \n",
    "    def count(self, arr):\n",
    "        self.__count += len(arr)\n",
    "        \n",
    "        return self.get()\n",
    "\n",
    "    def get(self):\n",
    "        return self.__count\n",
    "    \n",
    "    def reset(self):\n",
    "        self.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.distance = torch.nn.CosineSimilarity(dim=1)\n",
    "        self.distance = nn.DataParallel(self.distance, device_ids=[1, 2, 3])\n",
    "        \n",
    "    def predict(self, X_train, y_train, X_test, y_test, treshold):\n",
    "        start = time()\n",
    "        sim = torch.stack([self.distance(torch.stack([X] * 3), X_train) for X in X_test])\n",
    "        \n",
    "                \n",
    "        y_hat = self._get_y_hat(sim, treshold)\n",
    "        y = self._get_y_true(y_train, y_test)\n",
    "\n",
    "        return y, y_hat\n",
    "    def _get_y_hat(self, sim, treshold):\n",
    "        return sim > torch.tensor(treshold, device=device)\n",
    "    def _get_y_true(self, y_train, y_test):\n",
    "        return y_test[:, None] == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CV:\n",
    "    def __init__(self,  model, tresholds):\n",
    "        self.tresholds = tresholds\n",
    "        self.model = model\n",
    "        \n",
    "    def calculate(self, train_file, validation_file, chunksize=100000, validation_chunksize=1, validation_limit=None):\n",
    "        scores = []\n",
    "        \n",
    "        acc = BalancedAccuracyMeter()\n",
    "        counter = Counter()\n",
    "        validation_counter = Counter()\n",
    "        \n",
    "        for treshold in tresholds:\n",
    "            score = []\n",
    "            \n",
    "            validation_df = pd.read_csv(validation_file, \n",
    "                                        chunksize=validation_chunksize,\n",
    "                                        header=0,\n",
    "                                        converters={'image': read_string_array})\n",
    "            \n",
    "            for validation_chunk in validation_df:\n",
    "                start = time()\n",
    "                X_test, y_test = read_chunk(validation_chunk, device)\n",
    "                print('Validation read:', time() - start)\n",
    "                \n",
    "                if validation_limit and validation_counter.count(X_test) > validation_limit:\n",
    "                    break\n",
    "                \n",
    "                \n",
    "                \n",
    "                for chunk in train_df:\n",
    "                    print('Treshold', treshold,\n",
    "                          'Train:', counter.count(chunk),\n",
    "                          'Validation:', validation_counter.get())\n",
    "\n",
    "                    start = time()\n",
    "                    X_train, y_train = read_chunk(chunk, device)\n",
    "                    print('Train read:', time() - start)\n",
    "                    y, y_hat = self.model.predict(X_train, y_train, X_test, y_test, treshold)\n",
    "                    del X_train\n",
    "                    del y_train\n",
    "                    acc.add(y, y_hat)\n",
    "\n",
    "                accuracy = acc.calculate()\n",
    "                score.append(accuracy)\n",
    "                print('Accuracy:', torch.mean(accuracy))\n",
    "        \n",
    "                acc.reset()\n",
    "                counter.reset()\n",
    "                \n",
    "                del X_test\n",
    "                del y_test\n",
    "            score = torch.cat(score, 0)\n",
    "            print(score)\n",
    "            mean_score = torch.mean(score)\n",
    "            scores.append(mean_score)\n",
    "            validation_counter.reset()\n",
    "            \n",
    "        scores = torch.tensor(scores)\n",
    "        best_index = torch.argmax(scores)\n",
    "        best = self.tresholds[best_index]\n",
    "        best_score = scores[best_index]\n",
    "        \n",
    "        return best, best_score.cpu().numpy(), scores.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          start end step\n",
    "tresholds = list(np.arange(0.0, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CV(model, tresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_treshold(treshold, file='../data/treshold.npy'):\n",
    "    np.save(file, [treshold])\n",
    "def load_treshold(file='../data/treshold.npy'):\n",
    "    return np.load(file)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation read: 2.844519853591919\n",
      "Treshold 0.0 Train: 343350 Validation: 3000\n",
      "Train read: 20.031020879745483\n",
      "Accuracy: tensor(0.7309)\n",
      "Validation read: 0.004582405090332031\n",
      "Treshold 0.0 Train: 343350 Validation: 6000\n",
      "Train read: 1.2230401039123535\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.84 GiB (GPU 1; 10.92 GiB total capacity; 6.42 GiB already allocated; 2.83 GiB free; 6.44 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-06e5c58b9040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m350000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# best, best_score = cv.calculate(train_file, validation_file, chunksize=100, validation_chunksize=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-9a765767da99>\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self, train_file, validation_file, chunksize, validation_chunksize, validation_limit)\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train read:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-7a0d5197b761>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_train, y_train, X_test, y_test, treshold)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.84 GiB (GPU 1; 10.92 GiB total capacity; 6.42 GiB already allocated; 2.83 GiB free; 6.44 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "best, best_score, scores = cv.calculate(train_file, validation_file, chunksize=350000, validation_chunksize=3000, validation_limit=9000)\n",
    "# best, best_score = cv.calculate(train_file, validation_file, chunksize=100, validation_chunksize=10)\n",
    "best, best_score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_treshold(best.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Treshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(tresholds, scores)\n",
    "plt.savefig('0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresholds = list(np.arange( float(best - 0.1), float(best + 0.09), 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best, best_score, scores = cv.calculate(train_file, validation_file, chunksize=100000, validation_chunksize=1000, validation_limit=9000)\n",
    "best, best_score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_treshold(best.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Treshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(tresholds, scores)\n",
    "plt.savefig('1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = load_treshold()\n",
    "treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
